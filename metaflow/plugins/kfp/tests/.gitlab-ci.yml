# Barebones template to ensure pipeline is triggered
include:
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53' 
    file: 'environments/devex.yml'
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53'  
    file: 'blocks/aws.yml'
  - project: 'analytics/artificial-intelligence/ai-platform/aip-infrastructure/ci-templates/ci-cd-template'
    ref: '37d84c8a56036de2567f88f7ede7557566d3cb53'
    file: 'blocks/docker.yml'

.generate_docker_image_version:
  script: &generate-docker-image-version-before-script
  - |
    if [ -z "${DOCKER_REPO_URL}" ] || [ -z "${MAJOR_VERSION}" ] || [ -z "${MINOR_VERSION}" ]; then
      echo "No DOCKER_REPO_URL=${DOCKER_REPO_URL}, MAJOR_VERSION=${MAJOR_VERSION} or MINOR_VERSION=${MINOR_VERSION} provided."
      exit 1
    fi
  - IMAGE_TAG="${MAJOR_VERSION}.${MINOR_VERSION}.${CI_COMMIT_SHORT_SHA}.${CI_COMMIT_REF_SLUG}"
  - |
    # Unfortunately we require gawk for a number of commands, but mawk is typically installed by default and has different substr behaviour.
    awk_version=$(awk -W version | sed -n 1p | awk '{print $1}')
    offset=$(if [ "${awk_version}" == "GNU" ]; then echo 1; else echo 0; fi)
    # Grab the team name from the closest Gitlab group to the Artificial Intelligence umbrella group.
    DEFAULT_TEAM_NAME=$(echo $CI_PROJECT_PATH | awk -v offset=$offset '{ split($0,parts,"/artificial-intelligence/");print substr(parts[2],0,index(parts[2],"/")-offset) }')
    IMAGE_PATH=${ARTIFACT_NAME:-$CI_PROJECT_NAME}
    if [ ! -z "${TEAM_NAME}" ] || [ ! -z "${DEFAULT_TEAM_NAME}" ]; then
      # Only if we have successfully found a team name should we construct a path using it.
      IMAGE_PATH=${TEAM_NAME:-$DEFAULT_TEAM_NAME}/${IMAGE_PATH}
    fi
  - IMAGE_REPOSITORY=${DOCKER_REPO_URL}/${ORGANIZATION_NAME}/${IMAGE_PATH}
  - IMAGE_REPOSITORY_TAG=${IMAGE_REPOSITORY}:${IMAGE_TAG}
  # Log these versions as build artifacts for subsequent stages to utilize.
  - mkdir -p versions
  - echo ${IMAGE_TAG} > ${IMAGE_TAG_PATH}
  - echo ${IMAGE_REPOSITORY} > ${IMAGE_REPOSITORY_PATH}
  - echo ${IMAGE_REPOSITORY_TAG} > ${IMAGE_REPOSITORY_TAG_PATH}
  artifacts:
    paths:
    - versions
    expire_in: "6 months"

.export_shared_path:
  script: &export-shared-path
  - export CONTAINER_ID=$(docker ps -q -f "label=com.gitlab.gitlab-runner.job.id=$CI_JOB_ID" -f "label=com.gitlab.gitlab-runner.type=build")
  - export MOUNT_NAME=$(docker inspect $CONTAINER_ID -f "{{ range .Mounts }}{{ if eq .Destination \"/builds\" }}{{ .Source }}{{end}}{{end}}")
  - export SHARED_PATH=$MOUNT_NAME/$CI_PROJECT_PATH
  
build:
  stage: build
  script:
    - *generate-docker-image-version-before-script
    - docker build -f metaflow/plugins/kfp/dockerfiles/integration_testing_full_image/Dockerfile -t integration-testing-full-image:1.0 .
    # - docker login --username=hsezhiyan --password=$DOCKERHUB_PASSWORD
    - echo "$CR_PAT" | docker login -u USERNAME --password-stdin docker.pkg.github.com
    # - docker tag integration-testing-full-image:1.0 hsezhiyan/kfp-base:$CI_COMMIT_SHA
    - docker tag integration-testing-full-image:1.0 docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
    # - docker push hsezhiyan/kfp-base
    - docker push docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA

test:internal:
  extends: 
    - .devex_internal_eks # sets up AWS environment variables
    - .generate_kubeconfig # creates the .kube directory for the appropriate cluster
    - .export_shared_path
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *export-shared-path  
    - cp -r /root/.kube .
    - echo "$CR_PAT" | docker login -u USERNAME --password-stdin docker.pkg.github.com
    - docker pull docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
    - docker run 
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube
        --rm 
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION 
        docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.dev-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-dev/metaflow/ && 
          export METAFLOW_USER=hariharans@zillowgroup.com &&
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --tag $CI_COMMIT_SHA
        "

test:nonprod:
  extends: 
    - .devex_nonprod_eks
    - .generate_kubeconfig
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *export-shared-path  
    - cp -r /root/.kube .
    - docker pull docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
    - docker run
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube 
        --rm
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION 
        docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.stage-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing-dev && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-stage/metaflow/ && 
          export METAFLOW_USER=hariharans@zillowgroup.com &&
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --tag $CI_COMMIT_SHA
        "

test:prod:
  extends: 
    - .devex_prod_eks
    - .generate_kubeconfig
  variables:
    GIT_STRATEGY: none
    PIPELINE_VERSION: "1.0"
  stage: test
  script:
    - *export-shared-path 
    - cp -r /root/.kube .
    - docker run
        -v ${SHARED_PATH}/.kube:/home/zservice/.kube 
        --rm
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID 
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY 
        -e AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN 
        -e AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION  
        docker.pkg.github.com/zillow/metaflow/kfp-base:$CI_COMMIT_SHA
        bash -c "
          export KFP_RUN_URL_PREFIX=https://kubeflow.corp.prod-k8s.zg-aip.net/ && 
          export KFP_SDK_NAMESPACE=metaflow-integration-testing-prod && 
          export METAFLOW_DATASTORE_SYSROOT_S3=s3://aip-example-prod/metaflow/ &&
          export METAFLOW_USER=hariharans@zillowgroup.com && 
          cd /home/zservice/metaflow/metaflow/plugins/kfp/tests && 
          python -m pytest -s -n 2 run_integration_tests.py --tag $CI_COMMIT_SHA
        "